#!/usr/bin/env python3
"""
Helper script to create a fine-tuning config for custom tasks.

Usage:
    python scripts/create_finetune_config.py \
        --name my_custom_task \
        --datasets "user/dataset1" "user/dataset2" \
        --prompts "Pick up the cube" "Insert the peg" \
        --action_dim 14

This will print a config block that you can paste into config.py.
"""

import argparse


def create_config(
    name: str,
    datasets: list[str],
    prompts: list[str],
    action_dim: int = 14,
    num_steps: int = 30000,
    batch_size: int = 16,
) -> str:
    """Generate a training config block."""

    if len(datasets) != len(prompts):
        raise ValueError(f"Number of datasets ({len(datasets)}) must match number of prompts ({len(prompts)})")

    # Format repo_ids tuple
    repo_ids_str = ",\n                ".join(f'"{d}"' for d in datasets)

    # Format repo_id_to_prompt dict
    prompt_items = [f'"{d}": "{p}"' for d, p in zip(datasets, prompts)]
    prompts_str = ",\n                ".join(prompt_items)

    config = f'''
    # Custom fine-tuning config: {name}
    # Generated by create_finetune_config.py
    TrainConfig(
        name="{name}",
        model=pi0_config.Pi0Config(
            pi05=True,
            paligemma_variant="gemma_2b",
            action_expert_variant="gemma_300m",
            action_dim={action_dim},
            action_horizon=50,
            freeze_vision_backbone=True,
        ),
        data=MultiLeRobotDataConfig(
            repo_ids=(
                {repo_ids_str},
            ),
            repo_id_to_prompt={{
                {prompts_str},
            }},
            use_delta_joint_actions=False,
            adapt_to_pi={"True" if action_dim == 14 else "False"},
        ),
        weight_loader=weight_loaders.FlexibleCheckpointWeightLoader(
            "gs://openpi-assets/checkpoints/pi05_base/params"
        ),
        freeze_filter=nnx_utils.PathRegex(".*PaliGemma/llm/(?!.*_1).*"),
        lr_schedule=_optimizer.CosineDecaySchedule(
            warmup_steps=1_000,
            peak_lr=5e-5,
            decay_steps={num_steps},
            decay_lr=1e-6,
        ),
        num_train_steps={num_steps},
        batch_size={batch_size},
        save_interval=5_000,
        keep_period=10_000,
    ),
'''
    return config


def main():
    parser = argparse.ArgumentParser(
        description="Generate a fine-tuning config for custom tasks",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Single task
  python scripts/create_finetune_config.py \\
      --name pi06_my_task \\
      --datasets "myuser/my-robot-data" \\
      --prompts "Pick up the red cube"

  # Multi-task
  python scripts/create_finetune_config.py \\
      --name pi06_multi_task \\
      --datasets "user/pick-place" "user/pour-water" \\
      --prompts "Pick and place the object" "Pour water into the glass" \\
      --action_dim 7

After generating, paste the config into src/fla/training/config.py
""",
    )

    parser.add_argument("--name", required=True, help="Config name (e.g., pi06_my_task)")
    parser.add_argument("--datasets", nargs="+", required=True, help="LeRobot dataset repo IDs")
    parser.add_argument("--prompts", nargs="+", required=True, help="Task prompts for each dataset")
    parser.add_argument("--action_dim", type=int, default=14, help="Action dimension (7=single arm, 14=bimanual)")
    parser.add_argument("--num_steps", type=int, default=30000, help="Number of training steps")
    parser.add_argument("--batch_size", type=int, default=16, help="Batch size")

    args = parser.parse_args()

    config = create_config(
        name=args.name,
        datasets=args.datasets,
        prompts=args.prompts,
        action_dim=args.action_dim,
        num_steps=args.num_steps,
        batch_size=args.batch_size,
    )

    print("=" * 60)
    print("Generated Config (paste into src/fla/training/config.py)")
    print("=" * 60)
    print(config)
    print("=" * 60)
    print("\nNext steps:")
    print(f"1. Paste the config into src/fla/training/config.py")
    print(f"2. Run: python scripts/compute_norm_stats.py {args.name}")
    print(f"3. Run: python scripts/train.py {args.name} --exp-name v1")


if __name__ == "__main__":
    main()
